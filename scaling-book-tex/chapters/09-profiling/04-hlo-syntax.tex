\subsection{How to read an XLA op}

HLO isn't actually very hard to read, and it's very helpful for understanding what a given part of the trace above corresponds to. Here's an example op called fusion.3.

\begin{lstlisting}[language=C, basicstyle=\footnotesize\ttfamily, breaklines=true]
%fusion.3 = bf16[32,32,4096]{2,1,0:T(8,128)(2,1)S(1)} fusion(bf16[32,32,8192]{2,1,0:T(8,128)(2,1)S(1)} %fusion.32), kind=kCustom, calls=%all-reduce-scatter.3
\end{lstlisting}

Let's break this down into its pieces.

\begin{description}
\item[Op Name:] fusion.3

A dot or fusion op is a set of operations containing at most 1 matrix multiplication and possibly a bunch of related pointwise VPU-ops.

\item[Shape/layout:] \texttt{bf16[32,32,4096]}

This is the output shape of the op. We can see the dtype is bf16 (2 bytes per parameter) and \texttt{[32,32,4096]} is the shape.

\item[Layout:] \texttt{\{2,1,0:T(8,128)(2,1)\}}

\texttt{\{2,1,0:T(8,128)(2,1)\}} tells us the order of the axes in memory (column major, row major, etc.) and the array padding. More below.

\item[Memory location:] S(1)

S(1) tells us this array lives in VMEM. S(0) (sometimes omitted) is HBM. S(2) and S(3) are other memory spaces.

\item[Arguments:] \texttt{bf16[32,32,8192]\{2,1,0:T(8,128)(2,1)S(1)\} \%fusion.32}

This op has one input, a bf16 array called fusion.32 with a particular shape. This tells us what function feeds into this one.
\end{description}

Let's try to understand this notation a little more. Let's take this as a simple example:

\texttt{f32[3,5]\{1,0:T(2,2)\}}

which again tells us that this Op returns a float32 array of shape \texttt{[3, 5]} with a particular tiling \texttt{\{1,0:T(2,2)\}}. While tilings don't matter \emph{too} much, briefly, tilings tell us how an N-dimensional array is laid out sequentially in memory. Here's a diagram showing how this array is laid out:

\begin{figure}[htb]
\centering
\includegraphics[width=0.7\textwidth]{images/tiling.png}
\caption{Memory layout for \texttt{f32[3,5]\{1,0:T(2,2)\}} showing how the 2D array is tiled in physical memory. The tiling \texttt{T(2,2)} means the array is laid out in 2Ã—2 chunks, with row-major ordering within each tile.}
\label{fig:tiling}
\end{figure}

Within \texttt{\{1,0:T(2,2)\}}, the \texttt{1,0} part tells us the ordering of array dimensions in physical memory, from most minor to most major. You can read this part from right to left and pick out the corresponding dimensions in \texttt{f32[3,5]} to figure out the physical layout of the array. In this example, the physical layout is \texttt{[3,5]}, identical to the logical shape.

After that, \texttt{T(2,2)} tells us that the array is tiled in chunks of \texttt{(2, 2)} where within each chunk, the array has rows first (\textbf{row-major}), then columns, i.e. \texttt{(0, 0)} is followed by \texttt{(0, 1)}, then \texttt{(1, 0)} and \texttt{(1,1)}. Because of the \texttt{T(2, 2)} tiling, the array is padded to \texttt{[4, 6]}, expanding its memory usage by about 1.6x. For the big bf16 array given above, \texttt{bf16[32,32,8192]\{2,1,0:T(8,128)(2,1)S(1)\}}, we do \texttt{T(8,128)(2,1)} which tells us the array has two levels of tiling, an outer \texttt{(8, 128)} tiling and an inner \texttt{(2, 1)} tiling within that unit (used for bf16 so our loads are always multiples of 4 bytes). For example, here's \texttt{bf16[4,8]\{1,0,T(2,4)(2,1)\}} (colors are (2,4) tiles, red boxes are (2,1) tiles):

\begin{figure}[htb]
\centering
\includegraphics[width=0.6\textwidth]{images/tiling2.png}
\caption{Nested tiling example for \texttt{bf16[4,8]\{1,0,T(2,4)(2,1)\}} showing outer (2,4) tiles in different colors and inner (2,1) tiles outlined in red.}
\label{fig:tiling2}
\end{figure}

Tiling can affect how efficiently chunks of tensors can be loaded into VMEM and XLA will sometimes introduce copies that ``retile'' or ``re-layout'' a tensor inside a program, sometimes at non-trivial overhead.\footnote{JAX provides an experimental feature to work around this issue, by allowing XLA to compute its ``preferred'' layout for inputs to a program. When you ``just-in-time'' compile a program with \texttt{jax.jit}, you typically pass in ``mock'' inputs that tell JAX what shape and dtype to expect. These typically also carry tiling information that may not be optimal. Instead, you can specify the input layouts as AUTO, and \texttt{jax.jit} will return a layout that the jitted program prefers. You can then explicitly load the tensor in that layout to avoid inducing copies within the program.}
